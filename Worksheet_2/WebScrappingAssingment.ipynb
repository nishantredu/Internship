{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quesion 1 Soltuion\n",
    "def get_wikipedia_tags(url):\n",
    "    request = requests.get(url)\n",
    "    Soup = BeautifulSoup(request.content)\n",
    "    heading_tags = [\"h1\", \"h2\", \"h3\", \"h4\", 'h5', \"h6\", \"h7\"]\n",
    "    for tags in Soup.find_all(heading_tags):\n",
    "        print(tags.name + '->' + tags.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1->Main Page\n",
      "h1->Welcome to Wikipedia\n",
      "h2->From today's featured article\n",
      "h2->Did you know ...\n",
      "h2->In the news\n",
      "h2->On this day\n",
      "h2->Today's featured picture\n",
      "h2->Other areas of Wikipedia\n",
      "h2->Wikipedia's sister projects\n",
      "h2->Wikipedia languages\n",
      "h2->Navigation menu\n",
      "h3->\n",
      "Personal tools\n",
      "\n",
      "h3->\n",
      "Namespaces\n",
      "\n",
      "h3->\n",
      "Views\n",
      "\n",
      "h3->\n",
      "Search\n",
      "\n",
      "h3->\n",
      "Navigation\n",
      "\n",
      "h3->\n",
      "Contribute\n",
      "\n",
      "h3->\n",
      "Tools\n",
      "\n",
      "h3->\n",
      "Print/export\n",
      "\n",
      "h3->\n",
      "In other projects\n",
      "\n",
      "h3->\n",
      "Languages\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_wikipedia_tags(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2 Solution\n",
    "def get_imbd_data(url):\n",
    "    request = requests.get(url)\n",
    "    Soup = BeautifulSoup(request.content)\n",
    "    titles = []\n",
    "    years = []\n",
    "    ratings = []\n",
    "    for i,title in enumerate(Soup.find_all('td', class_=\"titleColumn\")):\n",
    "        name = title.find('a').text\n",
    "        year = title.find('span').text[1:-1]\n",
    "        titles.append(name)\n",
    "        years.append(year)\n",
    "\n",
    "        if i == 99:\n",
    "            break\n",
    "\n",
    "    for i, rating in enumerate(Soup.find_all('td', class_='ratingColumn imdbRating')):\n",
    "        rat=rating.find('strong').text\n",
    "        ratings.append(rat)\n",
    "        if i==99:\n",
    "            break\n",
    "\n",
    "    movies_data= pd.DataFrame({'Title':titles, 'Year of Release': years, 'Rating':ratings})\n",
    "    return movies_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year of Release</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Jagten</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>1959</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>1931</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Vertigo</td>\n",
       "      <td>1958</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Le fabuleux destin d'Amélie Poulain</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title Year of Release Rating\n",
       "0              The Shawshank Redemption            1994    9.2\n",
       "1                         The Godfather            1972    9.2\n",
       "2                       The Dark Knight            2008    9.0\n",
       "3                 The Godfather Part II            1974    9.0\n",
       "4                          12 Angry Men            1957    8.9\n",
       "..                                  ...             ...    ...\n",
       "95                               Jagten            2012    8.3\n",
       "96                   North by Northwest            1959    8.3\n",
       "97    M - Eine Stadt sucht einen Mörder            1931    8.3\n",
       "98                              Vertigo            1958    8.2\n",
       "99  Le fabuleux destin d'Amélie Poulain            2001    8.2\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_imbd_data(\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3 Solution\n",
    "def get_indian_imbd_data(url):\n",
    "    request = requests.get(url)\n",
    "    Soup = BeautifulSoup(request.content)\n",
    "    titles = []\n",
    "    years = []\n",
    "    ratings = []\n",
    "    for i,title in enumerate(Soup.find_all('td', class_=\"titleColumn\")):\n",
    "        name = title.find('a').text\n",
    "        year = title.find('span').text[1:-1]\n",
    "        titles.append(name)\n",
    "        years.append(year)\n",
    "\n",
    "        if i == 99:\n",
    "            break\n",
    "\n",
    "    for i, rating in enumerate(Soup.find_all('td', class_='ratingColumn imdbRating')):\n",
    "        rat=rating.find('strong').text\n",
    "        ratings.append(rat)\n",
    "        if i==99:\n",
    "            break\n",
    "\n",
    "    movies_data= pd.DataFrame({'Title':titles, 'Year of Release': years, 'Rating':ratings})\n",
    "    return movies_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year of Release</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>2003</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>1979</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>1987</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>2018</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Baasha</td>\n",
       "      <td>1995</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Masaan</td>\n",
       "      <td>2015</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Kahaani</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Baahubali 2: The Conclusion</td>\n",
       "      <td>2017</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Dil Chahta Hai</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Title Year of Release Rating\n",
       "0                      Jai Bhim            2021    8.4\n",
       "1                    Anbe Sivam            2003    8.4\n",
       "2                       Golmaal            1979    8.4\n",
       "3                       Nayakan            1987    8.4\n",
       "4             Pariyerum Perumal            2018    8.4\n",
       "..                          ...             ...    ...\n",
       "95                       Baasha            1995    8.0\n",
       "96                       Masaan            2015    8.0\n",
       "97                      Kahaani            2012    8.0\n",
       "98  Baahubali 2: The Conclusion            2017    8.0\n",
       "99               Dil Chahta Hai            2001    8.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_indian_imbd_data(\"https://www.imdb.com/india/top-rated-indian-movies/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shri Pranab Mukherjee (1935-2020)   25 July, 2012 to 25 July, 201\n",
      "Smt Pratibha Devisingh Patil (birth - 1934)   25 July, 2007 to 25 July, 201\n",
      "DR. A.P.J. Abdul Kalam (1931-2015)   25 July, 2002 to 25 July, 200\n",
      "Shri K. R. Narayanan (1920 - 2005)   25 July, 1997 to 25 July, 200\n",
      "Dr Shankar Dayal Sharma (1918-1999)   25 July, 1992 to 25 July, 199\n",
      "Shri R Venkataraman (1910-2009)   25 July, 1987 to 25 July, 199\n",
      "Giani Zail Singh (1916-1994)   25 July, 1982 to 25 July, 198\n",
      "Shri Neelam Sanjiva Reddy (1913-1996)   25 July, 1977 to 25 July, 198\n",
      "Dr. Fakhruddin Ali Ahmed (1905-1977)   24 August, 1974 to 11 February, 19\n",
      "Shri Varahagiri Venkata Giri (1894-1980)   3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 19\n",
      "Dr. Zakir Husain (1897-1969)   13 May, 1967 to 3 May, 19\n",
      "Dr. Sarvepalli Radhakrishnan (1888-1975)   13 May, 1962 to 13 May, 19\n",
      "Dr. Rajendra Prasad (1884-1963)    26 January, 1950 to 13 May, 19\n"
     ]
    }
   ],
   "source": [
    "# Question 4 Solution\n",
    "def indian_presidents(url):\n",
    "    request = requests.get(url)\n",
    "    Soup = BeautifulSoup(request.content)\n",
    "\n",
    "    for i, president in enumerate(Soup.find_all('div', class_='presidentListing')):\n",
    "        name = president.find('h3').text\n",
    "        term = president.find('p').text[16:-2]\n",
    "        print(name, \" \", term)\n",
    "        \n",
    "indian_presidents('https://presidentofindia.nic.in/former-presidents.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Men's ODI Team Rankings\n",
      "   Rank          Name Matches Points Ratings\n",
      "0    1   New Zealand      12  1,505     125\n",
      "1    2       England      22  2,756     125\n",
      "2    3      Pakistan      19  2,005     106\n",
      "3    4         India      22  2,304     105\n",
      "4    5     Australia      22  2,182      99\n",
      "5    6  South Africa      19  1,872      99\n",
      "6    7    Bangladesh      24  2,275      95\n",
      "7    8     Sri Lanka      28  2,609      93\n",
      "8    9   West Indies      32  2,306      72\n",
      "9   10   Afghanistan      18  1,238      69\n",
      "Mens Batsman Rankings\n",
      "    Rank                   Name Nationality Rating\n",
      "0     1             Babar Azam         PAK    892\n",
      "1     2            Imam-ul-Haq         PAK    815\n",
      "2     3            Virat Kohli         IND    811\n",
      "3     4           Rohit Sharma         IND    791\n",
      "4     5        Quinton de Kock          SA    789\n",
      "5     6            Ross Taylor          NZ    775\n",
      "6     7  Rassie van der Dussen          SA    769\n",
      "7     8         Jonny Bairstow         ENG    760\n",
      "8     9           David Warner         AUS    745\n",
      "9    10            Aaron Finch         AUS    727\n",
      "Men's ODI Bowler Rankings\n",
      "    Rank              Name Nationality Rating\n",
      "0     1       Trent Boult          NZ    726\n",
      "1     2      Chris Woakes         ENG    686\n",
      "2     3        Matt Henry          NZ    683\n",
      "3     4    Shaheen Afridi         PAK    681\n",
      "4     5    Jasprit Bumrah         IND    679\n",
      "5     6  Mujeeb Ur Rahman         AFG    676\n",
      "6     7    Josh Hazlewood         AUS    667\n",
      "7     8      Mehedi Hasan         BAN    661\n",
      "8     9     Mohammad Nabi         AFG    657\n",
      "9    10   Shakib Al Hasan         BAN    657\n"
     ]
    }
   ],
   "source": [
    "# Question 5 Solution\n",
    "# Part 1\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "def top_ten_mens_odi_team(url):\n",
    "    request = requests.get(url)\n",
    "    Soup = BeautifulSoup(request.content)\n",
    "    ranks = []\n",
    "    names = []\n",
    "    points = []\n",
    "    ratings= []\n",
    "    matches =[]\n",
    "#     For rank 1 team\n",
    "    top_data = Soup.find('tr', class_='rankings-block__banner')\n",
    "    top_rank = top_data.find('td', class_='rankings-block__banner--pos').text\n",
    "    top_name = top_data.find('span', class_='u-hide-phablet').text\n",
    "    top_matches = top_data.find('td', class_='rankings-block__banner--matches').text\n",
    "    top_points = top_data.find('td', class_='rankings-block__banner--points').text\n",
    "    top_rating = int(top_data.find('td', class_='rankings-block__banner--rating').text[3:-2])\n",
    "    ranks.append(top_rank)\n",
    "    names.append(top_name)\n",
    "    matches.append(top_matches)\n",
    "    points.append(top_points)\n",
    "    ratings.append(top_rating)\n",
    "#     print(top_rank, \" \", top_name, ' ', top_matches, ' ', top_points, ' ',top_rating)\n",
    "# For rest Teams\n",
    "\n",
    "    for i, data in enumerate(Soup.find_all('tr', class_='table-body')):\n",
    "        if i==9:\n",
    "            break\n",
    "        rpr = data.find_all('td')\n",
    "        rank = rpr[0].text\n",
    "        match = rpr[2].text\n",
    "        point = rpr[3].text\n",
    "        rating = rpr[4].text\n",
    "        name = data.find('span', class_='u-hide-phablet').text\n",
    "        ranks.append(rank)\n",
    "        names.append(name)\n",
    "        matches.append(match)\n",
    "        points.append(point)\n",
    "        ratings.append(rating)\n",
    "\n",
    "    odi_teams = pd.DataFrame({'Rank':ranks, 'Name':names, 'Matches':matches, 'Points':points, 'Ratings':ratings})\n",
    "    return odi_teams\n",
    "print(\"Men's ODI Team Rankings\\n\", top_ten_mens_odi_team(url))\n",
    "\n",
    "\n",
    "#Part 2\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi'\n",
    "\n",
    "def top_ten_mens_batsman(url): \n",
    "\n",
    "    request = requests.get(url)\n",
    "    Soup = BeautifulSoup(request.content)\n",
    "\n",
    "    ranks = []\n",
    "    names = []\n",
    "    nations = []\n",
    "    ratings = []\n",
    "    batContainer = Soup.find('div', class_='rankings-block__container')\n",
    "    toprank = int(batContainer.find('span', class_='rankings-block__pos-number').text)\n",
    "    topname = batContainer.find('div', class_='rankings-block__banner--name').text\n",
    "    topnation = batContainer.find('div', class_='rankings-block__banner--nationality').text[2:-5]\n",
    "    toprating = batContainer.find('div', class_='rankings-block__banner--nationality').text[-4:-1]\n",
    "    ranks.append(toprank)\n",
    "    names.append(topname)\n",
    "    nations.append(topnation)\n",
    "    ratings.append(toprating)\n",
    "    # print(toprank, \" \", topname, \" \", topnation, \" \", toprating)\n",
    "\n",
    "    for i, detail in enumerate(batContainer.find_all('tr', class_='table-body')):\n",
    "        rank=int(detail.find('span', class_='rankings-table__pos-number').text)\n",
    "        name = detail.find('td', class_='table-body__cell name').text[1:-1]\n",
    "        nation = detail.find('td', class_='table-body__cell nationality-logo').text[2:-1]\n",
    "        rating = int(detail.find('td', class_='table-body__cell u-text-right rating').text)\n",
    "        ranks.append(rank)\n",
    "        names.append(name)\n",
    "        nations.append(nation)\n",
    "        ratings.append(rating)\n",
    "    odi_men_batsman = pd.DataFrame({'Rank':ranks, 'Name':names, 'Nationality':nations, 'Rating':ratings})\n",
    "    return odi_men_batsman\n",
    "\n",
    "print('Mens Batsman Rankings\\n',top_ten_mens_batsman(url))\n",
    "      \n",
    "# Part 3 Solution      \n",
    "def top_ten_mens_allrounder(url):\n",
    "    request = requests.get(url)\n",
    "    Soup = BeautifulSoup(request.content)\n",
    "\n",
    "    ranks = []\n",
    "    names = []\n",
    "    nations = []\n",
    "    ratings = []\n",
    "    allContainer = Soup.find_all('div', class_='rankings-block__container')[1]\n",
    "    toprank = int(allContainer.find('span', class_='rankings-block__pos-number').text)\n",
    "    topname = allContainer.find('div', class_='rankings-block__banner--name').text\n",
    "    topnation = allContainer.find('div', class_='rankings-block__banner--nationality').text[2:-5]\n",
    "    toprating = allContainer.find('div', class_='rankings-block__banner--nationality').text[-4:-1]\n",
    "    ranks.append(toprank)\n",
    "    names.append(topname)\n",
    "    nations.append(topnation)\n",
    "    ratings.append(toprating)\n",
    "    # print(toprank, \" \", topname, \" \", topnation, \" \", toprating)\n",
    "\n",
    "    for i, detail in enumerate(allContainer.find_all('tr', class_='table-body')):\n",
    "        rank=int(detail.find('span', class_='rankings-table__pos-number').text)\n",
    "        name = detail.find('td', class_='table-body__cell name').text[1:-1]\n",
    "        nation = detail.find('td', class_='table-body__cell nationality-logo').text[2:-1]\n",
    "        rating = int(detail.find('td', class_='table-body__cell u-text-right rating').text)\n",
    "        ranks.append(rank)\n",
    "        names.append(name)\n",
    "        nations.append(nation)\n",
    "        ratings.append(rating)\n",
    "    odi_men_allrounder = pd.DataFrame({'Rank':ranks, 'Name':names, 'Nationality':nations, 'Rating':ratings})\n",
    "    return odi_men_allrounder\n",
    "\n",
    "print(\"Men's ODI Bowler Rankings\\n\",top_ten_mens_allrounder(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women's ODI Team Rankings\n",
      "   Rank          Name Matches Points Ratings\n",
      "0    1     Australia      29  4,837     167\n",
      "1    2  South Africa      32  3,949     123\n",
      "2    3       England      30  3,531     118\n",
      "3    4         India      29  2,889     100\n",
      "4    5   New Zealand      31  3,019      97\n",
      "5    6   West Indies      30  2,768      92\n",
      "6    7    Bangladesh      12    930      78\n",
      "7    8      Pakistan      30  1,962      65\n",
      "8    9     Sri Lanka       8    384      48\n",
      "9   10       Ireland       8    351      44\n",
      "Womens Batsman Rankings\n",
      "    Rank               Name Nationality Rating\n",
      "0     1       Alyssa Healy         AUS    785\n",
      "1     2     Natalie Sciver         ENG    750\n",
      "2     3        Beth Mooney         AUS    748\n",
      "3     4    Laura Wolvaardt          SA    713\n",
      "4     5        Meg Lanning         AUS    710\n",
      "5     6     Rachael Haynes         AUS    701\n",
      "6     7  Amy Satterthwaite          NZ    681\n",
      "7     8    Smriti Mandhana         IND    669\n",
      "8     9     Tammy Beaumont         ENG    659\n",
      "9    10       Ellyse Perry         AUS    642\n",
      "Women's ODI all Rounder Rankings\n",
      "    Rank              Name Nationality Rating\n",
      "0     1    Natalie Sciver         ENG    393\n",
      "1     2      Ellyse Perry         AUS    374\n",
      "2     3   Hayley Matthews          WI    338\n",
      "3     4    Marizanne Kapp          SA    338\n",
      "4     5       Amelia Kerr          NZ    335\n",
      "5     6  Ashleigh Gardner         AUS    269\n",
      "6     7     Deepti Sharma         IND    249\n",
      "7     8     Jess Jonassen         AUS    245\n",
      "8     9         Sune Luus          SA    223\n",
      "9    10   Katherine Brunt         ENG    221\n"
     ]
    }
   ],
   "source": [
    "# Question 6 Solution\n",
    "# Part 1\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "def top_ten_Womens_odi_team(url):\n",
    "    request = requests.get(url)\n",
    "    Soup = BeautifulSoup(request.content)\n",
    "    ranks = []\n",
    "    names = []\n",
    "    points = []\n",
    "    ratings= []\n",
    "    matches =[]\n",
    "#     For rank 1 team\n",
    "    top_data = Soup.find('tr', class_='rankings-block__banner')\n",
    "    top_rank = top_data.find('td', class_='rankings-block__banner--pos').text\n",
    "    top_name = top_data.find('span', class_='u-hide-phablet').text\n",
    "    top_matches = top_data.find('td', class_='rankings-block__banner--matches').text\n",
    "    top_points = top_data.find('td', class_='rankings-block__banner--points').text\n",
    "    top_rating = int(top_data.find('td', class_='rankings-block__banner--rating').text[3:-2])\n",
    "    ranks.append(top_rank)\n",
    "    names.append(top_name)\n",
    "    matches.append(top_matches)\n",
    "    points.append(top_points)\n",
    "    ratings.append(top_rating)\n",
    "#     print(top_rank, \" \", top_name, ' ', top_matches, ' ', top_points, ' ',top_rating)\n",
    "# For rest Teams\n",
    "\n",
    "    for i, data in enumerate(Soup.find_all('tr', class_='table-body')):\n",
    "        if i==9:\n",
    "            break\n",
    "        rpr = data.find_all('td')\n",
    "        rank = rpr[0].text\n",
    "        match = rpr[2].text\n",
    "        point = rpr[3].text\n",
    "        rating = rpr[4].text\n",
    "        name = data.find('span', class_='u-hide-phablet').text\n",
    "        ranks.append(rank)\n",
    "        names.append(name)\n",
    "        matches.append(match)\n",
    "        points.append(point)\n",
    "        ratings.append(rating)\n",
    "\n",
    "    odi_teams = pd.DataFrame({'Rank':ranks, 'Name':names, 'Matches':matches, 'Points':points, 'Ratings':ratings})\n",
    "    return odi_teams\n",
    "print(\"Women's ODI Team Rankings\\n\", top_ten_Womens_odi_team(url))\n",
    "\n",
    "\n",
    "#Part 2\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi'\n",
    "\n",
    "def top_ten_Womens_batsman(url): \n",
    "\n",
    "    request = requests.get(url)\n",
    "    Soup = BeautifulSoup(request.content)\n",
    "\n",
    "    ranks = []\n",
    "    names = []\n",
    "    nations = []\n",
    "    ratings = []\n",
    "    batContainer = Soup.find('div', class_='rankings-block__container')\n",
    "    toprank = int(batContainer.find('span', class_='rankings-block__pos-number').text)\n",
    "    topname = batContainer.find('div', class_='rankings-block__banner--name').text\n",
    "    topnation = batContainer.find('div', class_='rankings-block__banner--nationality').text[2:-5]\n",
    "    toprating = batContainer.find('div', class_='rankings-block__banner--nationality').text[-4:-1]\n",
    "    ranks.append(toprank)\n",
    "    names.append(topname)\n",
    "    nations.append(topnation)\n",
    "    ratings.append(toprating)\n",
    "    # print(toprank, \" \", topname, \" \", topnation, \" \", toprating)\n",
    "\n",
    "    for i, detail in enumerate(batContainer.find_all('tr', class_='table-body')):\n",
    "        rank=int(detail.find('span', class_='rankings-table__pos-number').text)\n",
    "        name = detail.find('td', class_='table-body__cell name').text[1:-1]\n",
    "        nation = detail.find('td', class_='table-body__cell nationality-logo').text[2:-1]\n",
    "        rating = int(detail.find('td', class_='table-body__cell u-text-right rating').text)\n",
    "        ranks.append(rank)\n",
    "        names.append(name)\n",
    "        nations.append(nation)\n",
    "        ratings.append(rating)\n",
    "    odi_men_batsman = pd.DataFrame({'Rank':ranks, 'Name':names, 'Nationality':nations, 'Rating':ratings})\n",
    "    return odi_men_batsman\n",
    "\n",
    "print('Womens Batsman Rankings\\n',top_ten_Womens_batsman(url))\n",
    "      \n",
    "# Part 3 Solution      \n",
    "def top_ten_Womens_allrounder(url):\n",
    "    request = requests.get(url)\n",
    "    Soup = BeautifulSoup(request.content)\n",
    "\n",
    "    ranks = []\n",
    "    names = []\n",
    "    nations = []\n",
    "    ratings = []\n",
    "    allContainer = Soup.find_all('div', class_='rankings-block__container')[2]\n",
    "    toprank = int(allContainer.find('span', class_='rankings-block__pos-number').text)\n",
    "    topname = allContainer.find('div', class_='rankings-block__banner--name').text\n",
    "    topnation = allContainer.find('div', class_='rankings-block__banner--nationality').text[2:-5]\n",
    "    toprating = allContainer.find('div', class_='rankings-block__banner--nationality').text[-4:-1]\n",
    "    ranks.append(toprank)\n",
    "    names.append(topname)\n",
    "    nations.append(topnation)\n",
    "    ratings.append(toprating)\n",
    "    # print(toprank, \" \", topname, \" \", topnation, \" \", toprating)\n",
    "\n",
    "    for i, detail in enumerate(allContainer.find_all('tr', class_='table-body')):\n",
    "        rank=int(detail.find('span', class_='rankings-table__pos-number').text)\n",
    "        name = detail.find('td', class_='table-body__cell name').text[1:-1]\n",
    "        nation = detail.find('td', class_='table-body__cell nationality-logo').text[2:-1]\n",
    "        rating = int(detail.find('td', class_='table-body__cell u-text-right rating').text)\n",
    "        ranks.append(rank)\n",
    "        names.append(name)\n",
    "        nations.append(nation)\n",
    "        ratings.append(rating)\n",
    "    odi_men_allrounder = pd.DataFrame({'Rank':ranks, 'Name':names, 'Nationality':nations, 'Rating':ratings})\n",
    "    return odi_men_allrounder\n",
    "\n",
    "print(\"Women's ODI all Rounder Rankings\\n\",top_ten_Womens_allrounder(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This 1st half ranks among the market’s worst o...</td>\n",
       "      <td>23 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/this-first-hal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What we can learn about inflation, consumers f...</td>\n",
       "      <td>32 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/investors-can-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to save money at the pump, with or without...</td>\n",
       "      <td>33 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/how-to-save-mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Instagram is testing new ways for teens to ver...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/instagram-test...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Proposed changes to retirement system get appr...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/proposed-chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>High inflation has 58% feeling insecure about ...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/as-inflation-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Supreme Court strikes down NY gun law restrict...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/supreme-court-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FDA bans Juul e-cigarettes as government pursu...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/fda-bans-juul-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tax return backlog is still 'crushing the IRS’...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/tax-return-bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Education Department to cancel student loan de...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/education-depa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Watch Jerome Powell testify to Congress on the...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/watch-jerome-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jan. 6 hearing to spotlight Trump's pressure o...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/jan-6-hearing-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Warren Buffett buys another $500 million of Oc...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/buffett-buys-5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A 30-year Wall Street veteran on his tips for ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/30-year-wall-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chinese EV maker Nio says a car fell from thir...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/nio-car-falls-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>JPMorgan sees no recession, 28% S&amp;P 500 comeba...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/jpmorgan-midye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chipotle restaurant in Maine becomes chain's f...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/chipotle-resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>JPMorgan upgrades Funko, says toy stock has up...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/jpmorgan-upgra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What Cramer is watching Thursday — Meta's big ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/cramer-thursda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What Biden's upcoming student loan forgiveness...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/what-bidens-st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bethenny Frankel's top spending advice: 'It ha...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/bethenny-frank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Forget Silicon Valley—these 10 small towns are...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/10-small-citie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4 side hustles for recent college graduates: O...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/side-hustles-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>United Airlines will cut 12% of Newark flights...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/united-airline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5 things to know before the stock market opens...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/5-things-to-kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Thursday's biggest analyst calls: Snowflake, S...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/thursdays-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Can media companies weather a recession? Their...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/media-executiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Stocks making the biggest moves premarket: Acc...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BofA cuts Netflix price target, warns of highe...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/bank-of-americ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Olive Garden's parent company Darden beats ear...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/23/darden-restaur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline         Time  \\\n",
       "0   This 1st half ranks among the market’s worst o...   23 Min Ago   \n",
       "1   What we can learn about inflation, consumers f...   32 Min Ago   \n",
       "2   How to save money at the pump, with or without...   33 Min Ago   \n",
       "3   Instagram is testing new ways for teens to ver...   1 Hour Ago   \n",
       "4   Proposed changes to retirement system get appr...   1 Hour Ago   \n",
       "5   High inflation has 58% feeling insecure about ...   1 Hour Ago   \n",
       "6   Supreme Court strikes down NY gun law restrict...  2 Hours Ago   \n",
       "7   FDA bans Juul e-cigarettes as government pursu...  2 Hours Ago   \n",
       "8   Tax return backlog is still 'crushing the IRS’...  2 Hours Ago   \n",
       "9   Education Department to cancel student loan de...  2 Hours Ago   \n",
       "10  Watch Jerome Powell testify to Congress on the...  2 Hours Ago   \n",
       "11  Jan. 6 hearing to spotlight Trump's pressure o...  3 Hours Ago   \n",
       "12  Warren Buffett buys another $500 million of Oc...  3 Hours Ago   \n",
       "13  A 30-year Wall Street veteran on his tips for ...  3 Hours Ago   \n",
       "14  Chinese EV maker Nio says a car fell from thir...  3 Hours Ago   \n",
       "15  JPMorgan sees no recession, 28% S&P 500 comeba...  3 Hours Ago   \n",
       "16  Chipotle restaurant in Maine becomes chain's f...  3 Hours Ago   \n",
       "17  JPMorgan upgrades Funko, says toy stock has up...  3 Hours Ago   \n",
       "18  What Cramer is watching Thursday — Meta's big ...  3 Hours Ago   \n",
       "19  What Biden's upcoming student loan forgiveness...  3 Hours Ago   \n",
       "20  Bethenny Frankel's top spending advice: 'It ha...  3 Hours Ago   \n",
       "21  Forget Silicon Valley—these 10 small towns are...  4 Hours Ago   \n",
       "22  4 side hustles for recent college graduates: O...  4 Hours Ago   \n",
       "23  United Airlines will cut 12% of Newark flights...  4 Hours Ago   \n",
       "24  5 things to know before the stock market opens...  4 Hours Ago   \n",
       "25  Thursday's biggest analyst calls: Snowflake, S...  4 Hours Ago   \n",
       "26  Can media companies weather a recession? Their...  5 Hours Ago   \n",
       "27  Stocks making the biggest moves premarket: Acc...  5 Hours Ago   \n",
       "28  BofA cuts Netflix price target, warns of highe...  5 Hours Ago   \n",
       "29  Olive Garden's parent company Darden beats ear...  5 Hours Ago   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.cnbc.com/2022/06/23/this-first-hal...  \n",
       "1   https://www.cnbc.com/2022/06/23/investors-can-...  \n",
       "2   https://www.cnbc.com/2022/06/23/how-to-save-mo...  \n",
       "3   https://www.cnbc.com/2022/06/23/instagram-test...  \n",
       "4   https://www.cnbc.com/2022/06/23/proposed-chang...  \n",
       "5   https://www.cnbc.com/2022/06/23/as-inflation-r...  \n",
       "6   https://www.cnbc.com/2022/06/23/supreme-court-...  \n",
       "7   https://www.cnbc.com/2022/06/23/fda-bans-juul-...  \n",
       "8   https://www.cnbc.com/2022/06/23/tax-return-bac...  \n",
       "9   https://www.cnbc.com/2022/06/23/education-depa...  \n",
       "10  https://www.cnbc.com/2022/06/23/watch-jerome-p...  \n",
       "11  https://www.cnbc.com/2022/06/23/jan-6-hearing-...  \n",
       "12  https://www.cnbc.com/2022/06/23/buffett-buys-5...  \n",
       "13  https://www.cnbc.com/2022/06/23/30-year-wall-s...  \n",
       "14  https://www.cnbc.com/2022/06/23/nio-car-falls-...  \n",
       "15  https://www.cnbc.com/2022/06/23/jpmorgan-midye...  \n",
       "16  https://www.cnbc.com/2022/06/23/chipotle-resta...  \n",
       "17  https://www.cnbc.com/2022/06/23/jpmorgan-upgra...  \n",
       "18  https://www.cnbc.com/2022/06/23/cramer-thursda...  \n",
       "19  https://www.cnbc.com/2022/06/23/what-bidens-st...  \n",
       "20  https://www.cnbc.com/2022/06/23/bethenny-frank...  \n",
       "21  https://www.cnbc.com/2022/06/23/10-small-citie...  \n",
       "22  https://www.cnbc.com/2022/06/23/side-hustles-f...  \n",
       "23  https://www.cnbc.com/2022/06/23/united-airline...  \n",
       "24  https://www.cnbc.com/2022/06/23/5-things-to-kn...  \n",
       "25  https://www.cnbc.com/2022/06/23/thursdays-anal...  \n",
       "26  https://www.cnbc.com/2022/06/23/media-executiv...  \n",
       "27  https://www.cnbc.com/2022/06/23/stocks-making-...  \n",
       "28  https://www.cnbc.com/2022/06/23/bank-of-americ...  \n",
       "29  https://www.cnbc.com/2022/06/23/darden-restaur...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUestion 7 Solution\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "def get_news_data(url):\n",
    "    request = requests.get(url)\n",
    "    Soup = BeautifulSoup(request.content)\n",
    "    headlines = []\n",
    "    urls = []\n",
    "    times = []\n",
    "\n",
    "    for i, data in enumerate(Soup.find_all('li',class_='LatestNews-item')):\n",
    "        title = data.find('a', href=True, class_='LatestNews-headline')\n",
    "        headline = title.text\n",
    "        link = title['href']\n",
    "        time = data.find('time', class_='LatestNews-timestamp').text\n",
    "        headlines.append(headline)\n",
    "        urls.append(link)\n",
    "        times.append(time)\n",
    "\n",
    "    news = pd.DataFrame({'Headline':headlines, 'Time':times, 'Link':urls})\n",
    "    return news\n",
    "get_news_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>URL</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>October 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>August 1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>June 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>February 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>April 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>February 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>August 1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>March 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>February 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>October 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>August 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>April 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>December 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>August 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>September 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>June 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>December 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>September 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>May 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>January 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>December 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>February 2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more   \n",
       "2                   Prakken, Henry, Sartor, Giovanni    \n",
       "3                                 Boden, Margaret A.    \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more   \n",
       "5                                        Miller, Tim    \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.    \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more   \n",
       "14                      Blum, Avrim L., Langley, Pat    \n",
       "15                   Arora, Saurabh, Doshi, Prashant    \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders    \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    \n",
       "19                      Riveiro, Maria, Thill, Serge    \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...   \n",
       "22                      Kohavi, Ron, John, George H.    \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...   \n",
       "24                                   Ying, Mingsheng    \n",
       "\n",
       "                                                  URL            Time  \n",
       "0   https://www.sciencedirect.com/science/article/...    October 2021  \n",
       "1   https://www.sciencedirect.com/science/article/...    October 2021  \n",
       "2   https://www.sciencedirect.com/science/article/...    October 2015  \n",
       "3   https://www.sciencedirect.com/science/article/...     August 1998  \n",
       "4   https://www.sciencedirect.com/science/article/...       June 2017  \n",
       "5   https://www.sciencedirect.com/science/article/...   February 2019  \n",
       "6   https://www.sciencedirect.com/science/article/...      April 2021  \n",
       "7   https://www.sciencedirect.com/science/article/...   February 2015  \n",
       "8   https://www.sciencedirect.com/science/article/...     August 1999  \n",
       "9   https://www.sciencedirect.com/science/article/...      March 2020  \n",
       "10  https://www.sciencedirect.com/science/article/...   February 2021  \n",
       "11  https://www.sciencedirect.com/science/article/...    October 2007  \n",
       "12  https://www.sciencedirect.com/science/article/...     August 2016  \n",
       "13  https://www.sciencedirect.com/science/article/...      April 2021  \n",
       "14  https://www.sciencedirect.com/science/article/...   December 1997  \n",
       "15  https://www.sciencedirect.com/science/article/...     August 2021  \n",
       "16  https://www.sciencedirect.com/science/article/...  September 2021  \n",
       "17  https://www.sciencedirect.com/science/article/...       June 2021  \n",
       "18  https://www.sciencedirect.com/science/article/...   December 2016  \n",
       "19  https://www.sciencedirect.com/science/article/...  September 2021  \n",
       "20  https://www.sciencedirect.com/science/article/...        May 2021  \n",
       "21  https://www.sciencedirect.com/science/article/...    January 2014  \n",
       "22  https://www.sciencedirect.com/science/article/...   December 1997  \n",
       "23  https://www.sciencedirect.com/science/article/...    October 2021  \n",
       "24  https://www.sciencedirect.com/science/article/...   February 2010  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 8 Solution\n",
    "\n",
    "url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "def get_ai_articles(url):\n",
    "    request = requests.get(url)\n",
    "    Soup = BeautifulSoup(request.content)\n",
    "    titles = []\n",
    "    links=[]\n",
    "    authors = []\n",
    "    times = []\n",
    "    for i,data in enumerate(Soup.find_all('li', class_='sc-9zxyh7-1 sc-9zxyh7-2 exAXfr jQmQZp')):\n",
    "        name = data.find('h2', class_='sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR').text\n",
    "        link = data.find('a', href=True,class_='sc-5smygv-0 nrDZj')['href']\n",
    "        author = data.find('span', class_='sc-1w3fpd7-0 pgLAT').text\n",
    "        time = data.find('span', class_='sc-1thf9ly-2 bKddwo').text\n",
    "        titles.append(name)\n",
    "        links.append(link)\n",
    "        authors.append(author)\n",
    "        times.append(time)\n",
    "\n",
    "    articles = pd.DataFrame({'Title':titles, 'Authors':authors, 'URL':links, 'Time':times})\n",
    "    return articles\n",
    "get_ai_articles(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>ImageURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World Cafe</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B Que</td>\n",
       "      <td>rth Indian</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29</td>\n",
       "      <td>North Indian, Mughlai, Desserts, Beverages</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Glasshouse</td>\n",
       "      <td>European, Italian, Asian, Continental</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Name  \\\n",
       "0                    Castle Barbeque   \n",
       "1                    Jungle Jamboree   \n",
       "2                    Castle Barbeque   \n",
       "3                         Cafe Knosh   \n",
       "4               The Barbeque Company   \n",
       "5                        India Grill   \n",
       "6                     Delhi Barbeque   \n",
       "7   The Monarch - Bar Be Que Village   \n",
       "8                         World Cafe   \n",
       "9                  Indian Grill Room   \n",
       "10                   Mad 4 Bar B Que   \n",
       "11                       Barbeque 29   \n",
       "12                        Glasshouse   \n",
       "\n",
       "                                       Cuisine  \\\n",
       "0                        North Indian, Chinese   \n",
       "1                 North Indian, Asian, Italian   \n",
       "2                        Chinese, North Indian   \n",
       "3                         Italian, Continental   \n",
       "4                        North Indian, Chinese   \n",
       "5                        North Indian, Italian   \n",
       "6                                 North Indian   \n",
       "7                                 North Indian   \n",
       "8                        North Indian, Italian   \n",
       "9                        North Indian, Mughlai   \n",
       "10                                  rth Indian   \n",
       "11  North Indian, Mughlai, Desserts, Beverages   \n",
       "12       European, Italian, Asian, Continental   \n",
       "\n",
       "                                             Location Ratings  \\\n",
       "0                      Connaught Place, Central Delhi     4.3   \n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi     4.3   \n",
       "2              Pacific Mall,Tagore Garden, West Delhi     4.3   \n",
       "3   The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "4                  Gardens Galleria,Sector 38A, Noida     4.3   \n",
       "5                Hilton Garden Inn,Saket, South Delhi     4.3   \n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi     4.3   \n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad     4.3   \n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad     4.3   \n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "10                               Sector 29, Faridabad     4.3   \n",
       "11                                     NIT, Faridabad     4.3   \n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec...     4.3   \n",
       "\n",
       "                                             ImageURL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 9 Solution\n",
    "url = 'https://www.dineout.co.in/delhi-restaurants/buffet-special'\n",
    "def get_restaurants_data(url):\n",
    "    request = requests.get(url)\n",
    "    Soup = BeautifulSoup(request.content)\n",
    "\n",
    "    names = []\n",
    "    ratings = []\n",
    "    cuisines = []\n",
    "    locations = []\n",
    "    imageURLS=[]\n",
    "\n",
    "    for i, data in enumerate(Soup.find_all('div', class_='restnt-main-wrap clearfix')):\n",
    "        name = data.find('a', class_='restnt-name ellipsis').text\n",
    "        rating = data.find('div', class_='restnt-rating rating-4 hide').text\n",
    "        cuisine = data.find('span', class_='double-line-ellipsis').text[25:]\n",
    "        location = data.find('div', class_='restnt-loc ellipsis').text\n",
    "        imageURL = data.find(class_='no-img')['data-src']\n",
    "\n",
    "        names.append(name)\n",
    "        ratings.append(rating)\n",
    "        cuisines.append(cuisine)\n",
    "        locations.append(location)\n",
    "        imageURLS.append(imageURL)\n",
    "    restaurants = pd.DataFrame({'Name':names, 'Cuisine':cuisines, 'Location':locations, 'Ratings':ratings, 'ImageURL':imageURLS})\n",
    "    return restaurants\n",
    "get_restaurants_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>H5 index</th>\n",
       "      <th>H5 Median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>414</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>410</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>391</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>356</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>345</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Frontiers in Immunology</td>\n",
       "      <td>134</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Small</td>\n",
       "      <td>134</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Nature Immunology</td>\n",
       "      <td>133</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>JAMA Oncology</td>\n",
       "      <td>133</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>The Lancet Neurology</td>\n",
       "      <td>133</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                              Title H5 index H5 Median\n",
       "0     1.                                             Nature      414       607\n",
       "1     2.                The New England Journal of Medicine      410       704\n",
       "2     3.                                            Science      391       564\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      356       583\n",
       "4     5.                                         The Lancet      345       600\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                            Frontiers in Immunology      134       177\n",
       "96   97.                                              Small      134       173\n",
       "97   98.                                  Nature Immunology      133       210\n",
       "98   99.                                      JAMA Oncology      133       202\n",
       "99  100.                               The Lancet Neurology      133       200\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 10 Solution\n",
    "url = 'https://scholar.google.com/citations?view_op=top_venues&hl=en'\n",
    "def get_publications(url):\n",
    "    request = requests.get(url)\n",
    "    Soup = BeautifulSoup(request.content)\n",
    "    ranks = []\n",
    "    titles = []\n",
    "    h5is = []\n",
    "    h5ms = []\n",
    "    table = Soup.find('table', class_='gsc_mp_table')\n",
    "    for i,data in enumerate(table.find_all('tr')):\n",
    "        if i==0:\n",
    "            continue\n",
    "        ranks.append(data.find(class_='gsc_mvt_p').text)\n",
    "        titles.append(data.find(class_='gsc_mvt_t').text)\n",
    "        h5is.append(data.find_all(class_='gsc_mvt_n')[0].text)\n",
    "        h5ms.append(data.find_all(class_='gsc_mvt_n')[1].text)\n",
    "    publications = pd.DataFrame({'Rank':ranks, 'Title':titles, 'H5 index':h5is, 'H5 Median':h5ms})\n",
    "    return publications\n",
    "get_publications(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
